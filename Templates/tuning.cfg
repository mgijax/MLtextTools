# Config params for tuning experiments
[DEFAULT]

[TRAINING_DATA]
SAMPLE_DATA_LIB: sampleDataLib.py
# name of the sampleDataLib to import if reading training data from sample files
# OR "None" if getting traing data from sklearn load_files()

SAMPLE_OBJ_TYPE_NAME: PrimTriageClassifiedSample
# The name of the python Sample class if using a sampleDataLib
# OR "None" if getting traing data from sklearn load_files()

DATA_DIR: ./data/dec2020/LegendsWords/Proc1
# If using a sampleDataLib, these params specify where the training and
#  (optionally) the validation sample data files are
#
# If using sklearn load_files(), these specify their respective directory paths
TRAINING_SET: %(DATA_DIR)s/trainSet.txt
VALIDATION_SET: %(DATA_DIR)s/valSet.txt
# if VALIDATION_SET is None, then the validation set will be randomly selected
#  from the training set at tuning script runtime


[CLASS_NAMES]
# If using a sampleDataLib, these params will be set from the
#   SAMPLE_OBJ_TYPE and the values here will be ignored

# See sklearn.metrics:   confusion_matrix,  classification_report
#   make_scorer, fbeta_score, precision_score, recall_score

#y_class_names: ['no', 'yes']
# The labels matching y_values from the training set: y_class_names[y_val]= name
# These should be the classification labels in alpha order
# These match training set directory names used by sklearn.datasets.load_files()

#y_class_to_score: 1
# the index in y_class_names to score,
#   i.e., compute precision, recall, f-score, etc.
# This class is used in the grid search scoring to select the best model.

#rpt_class_names: ['yes', 'no']
# Order + labels we want to report in confusion matrix and other rpts.

#rpt_class_mapping: [ 1, 0 ]
# List of y_values to rpt in confusion matrix and other reports.
# rpt_class_mapping[y_val] maps to rpt_class_names[]


[MODEL_TUNING]
rpt_classification_report_num: 2
# How many class_names to show in classification_report.
# These classes will be in rpt_class_mapping order

NUM_JOBS: 1
# number of parallel jobs to use when running GridSearch

TUNING_INDEX_FILE: index.out
# Where to write index file during tuning runs

GRIDSEARCH_BETA: 2
# Fscore beta for comparing params in GridSearch

COMPARE_BETA: 2
# use when comparing different models (outside GS)

VALIDATION_SPLIT: 0.20
# fraction of training set to use for validation set if it is being pulled
#  from the training set at tuning script runtime

NUM_CV: 5
# num of GridSearch cross validation fits (folds) to use
